# Инструкция по развертыванию LLM на сервере и создание интерфейса к нему через VLLM

1. Арендуем компьютер с ГПУ в облаке и настраиваем его.
2. Запускаем API сервер с инференсом LLM (деплоим LLM).
3. Запускаем веб интерфейс для чата с запущенной LLM (показываем LLM).

Подробнее в .ipynb
